{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Science Fair Project Code Summary and Explanation.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmOGqdb9Ywar",
        "colab_type": "text"
      },
      "source": [
        "# **Science Fair Project**\n",
        "**Project Goal:**\n",
        "\n",
        "To create a novel deep learning architecture method that could improve upon previous methods, using a method similar to boosting in machine learning.\n",
        "\n",
        "**Basic Explanation of Model:**\n",
        "\n",
        "A first deep learning model is trained on the original data. The training data that the first model misclassifies is then used to train a second model. That second model is then finetuned on the whole dataset. The training data that the second model misclassifies is then used to train a third model. That third model is then also finetuned on the whole dataset. The training data that the third model misclassifies is then used to finetune the first model.\n",
        "\n",
        "After this, the predictions from all 3 models are then used as training data for a final Artificial Neural Network which makes combined predictions. Pictured below is a visual representation of the process.\n",
        "\n",
        "![alt text](https://lh6.googleusercontent.com/QRKAMWUAlJ__bRkQeVygT5IjJQ4n8H9aXA9o0SIk0t7FjoiygbWRR9Ar5hq0I_8tPd9GIdZMVenbvAYX0pQHe9dFC6ilo2GHVph1VEFa)\n",
        "\n",
        "**Challenges:**\n",
        "\n",
        "The proposed architecture had to go through many iterations. The first model didn't contain any finetuning, and only worked on certain datasets. The second model had finetuning for both the 2nd and 3rd models, but not for the first, and did not work as intended. Finally, the third iteration of the model featured the original model finetuning, allowing the model to go full circle and have each model improve on eachother's weaknesses.\n",
        "\n",
        "Also, there were many challenges not related to the results of the finished product. The procedure was applied on traditional machine learning applications (i.e. those in csv format), but did not produce any significant results despite significant experimentation with structure and hyperparameters, and it actually made performance decrease.\n",
        "\n",
        "Also, there were other challenges related to portions of the project that were eventually scrapped. The project started as a driver safety project, with the intent to build an accident hotspot app. Said app was built, but the project continued to expand to detecting horizontal gaze nystagmus in apps, and then classifying distracted driver behavior from images. The distracted driver image classification ended up being the strongest portion of the project, and we scrapped the previous portions to focus on the innovative architecture we developed.\n",
        "\n",
        "On top of all these problems, the project itself was a massive challenge, as when we started this project a little under than a year ago, neither of us knew how to code. We spent many sleepless nights working and persevering through complications and learned valuable skills in machine learning.\n",
        "\n",
        "**Reception**\n",
        "\n",
        "For our project, we were able to achieve 2nd Place in the category of Robotics and Intelligent Machines at the Texas Science and Engineering Fair (TXSEF).\n",
        "\n",
        "We also summarized the results of our work in a professional-style paper and submitted it to multiple competitions to share our concept with the machine learning community to validate and build upon.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejvGRGrXCDAH",
        "colab_type": "text"
      },
      "source": [
        "# **Section 1 - Image Classification**\n",
        "\n",
        "This section tested the architecture against the popular CiFAR-10 Dataset, with 10 classes\n",
        "\n",
        "This section was done by my partner, so excuse it if it is a little jumbled, because I wasn't quite sure how to order it. Since I didn't want to delete any critical part of the process, I simply copy and pasted the original code. In terms of understanding how the model works, I would recommend looking at the latter two sections (my sections), as they are clearer, edited to be more succint, and better demonstrate the goal. This first section did achieve more significant results, due to the difference in data tested (Image vs. database data; Deep Learning Models vs ANN's)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37IVqTef-3zI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint('cnn1_cifar10.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
        "\n",
        "model1_history = model1.fit_generator(datagen.flow(x_train, y_train_cat, batch_size=batch_size),\\\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=20,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test_cat),callbacks=[LearningRateScheduler(lr_schedule),checkpoint])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_6-SlI0-_2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import numpy as np\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "  lrate = 0.001\n",
        "  if epoch > 75:\n",
        "    lrate = 0.0005\n",
        "  if epoch > 100:\n",
        "    lrate = 0.0003\n",
        "  return lrate\n",
        " \n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0\n",
        "\n",
        "#z-score\n",
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)\n",
        " \n",
        "num_classes = 10\n",
        "y_train_cat = np_utils.to_categorical(y_train,num_classes)\n",
        "y_test_cat = np_utils.to_categorical(y_test,num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpjHuiARl7_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "datagen.fit(x_train)\n",
        " \n",
        "#training\n",
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R44LZwwwgdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model1 = load_model('cnn1_cifar10.h5')\n",
        "model2 = load_model('cnn2_cifar10_finetuned.h5')\n",
        "model3 = load_model('cnn3_cifar10_finetuned_20epochs.h5')\n",
        "model4 = load_model('cnn4_cifar10_finetuned.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KK4egXuY7xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# asses model performance & RETURN predicted values\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "def performance(model, compare_imgs, right_classes):\n",
        "  predictions_train = model.predict(compare_imgs)\n",
        "  rounded_real_train = []\n",
        "  for item in predictions_train:\n",
        "    maxx = max(item)\n",
        "    rounded_real_train.append(np.where(item==maxx)[0][0])\n",
        "\n",
        "  print(classification_report(right_classes, rounded_real_train))  \n",
        "  print(confusion_matrix(right_classes,rounded_real_train))\n",
        "  return rounded_real_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnI8mHjiJ0b2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1_wrong_indexes,model1_wrong_imgs,model1_wrong_img_class  = generate_error_imgs2(model1_revist_pred_train,x_train,y_train)\n",
        "model1_wrong_imgs = np.array(model1_wrong_imgs)\n",
        "\n",
        "model1_wrong_img_class = np.array(model1_wrong_img_class)\n",
        "model1_wrong_img_class_cat = np_utils.to_categorical(model1_wrong_img_class,num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drO5-OqW_xQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "array = model1_pred != y_test_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83IcPQ6h_p3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1_pred = performance(model1,x_test,y_test)\n",
        "model2_pred = performance(model2,x_test,y_test)\n",
        "model3_pred = performance(model3,x_test,y_test)\n",
        "model4_pred = performance(model4,x_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Reas0vzuNrJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def progress_count(predictions1, predictions2, predictions3, predictions4, true_values):\n",
        "  first_wrong = (predictions1 != true_values)\n",
        "  second_wrong = (predictions2 != true_values)\n",
        "  third_wrong = (predictions3 != true_values)\n",
        "  fourth_wrong = (predictions4 != true_values)\n",
        "  second_and_third_wrong = third_wrong.copy()\n",
        "  num_second_third_overwrong=0\n",
        "  num_first_second_fourth_overwrong=0\n",
        "  num_first_third_fourth_overwrong=0\n",
        "  num_second_third_fourth_overwrong=0\n",
        "  num_first_second_third_fourth_overwrong=0\n",
        "  \n",
        "  num_first_wrong = sum(first_wrong)\n",
        "  num_first_second_wrong = 0\n",
        "  num_first_third_wrong = 0\n",
        "  \n",
        "  num_second_third_wrong = 0\n",
        "  \n",
        "  num_first_fourth_wrong = 0\n",
        "  num_second_fourth_wrong = 0\n",
        "  num_third_fourth_wrong = 0\n",
        "  num_NET_third_first_wrong = 0\n",
        "  \n",
        "  index0 = -1\n",
        "  for result in second_wrong:\n",
        "    index0 +=1\n",
        "    \n",
        "    if result == 1 and result == first_wrong[index0]:\n",
        "      num_first_second_wrong += 1\n",
        "    if result == 1 and third_wrong[index0]==0:\n",
        "      second_and_third_wrong[index0]=1\n",
        "  num_second_else_wrong = sum(second_wrong)-num_first_second_wrong\n",
        "\n",
        "  index1 = -1\n",
        "  for result1 in third_wrong:\n",
        "    index1 += 1\n",
        "    if result1 == 1 and result1 == first_wrong[index1]:\n",
        "      num_first_third_wrong += 1\n",
        "    if result1 == 1 and result1== second_wrong[index1]:\n",
        "      num_second_third_wrong += 1\n",
        "    if result1 == 1 and result1== second_wrong[index1] and result1 == first_wrong[index1]:\n",
        "      num_second_third_overwrong += 1\n",
        "  num_third_else_wrong = sum(third_wrong)-num_first_third_wrong-num_second_third_wrong+num_second_third_overwrong\n",
        "\n",
        "  index2 = -1\n",
        "  for result2 in second_and_third_wrong:\n",
        "    index2+=1\n",
        "    if result2 == 1 and result2 == first_wrong[index2]:\n",
        "      num_NET_third_first_wrong+= 1\n",
        "  \n",
        "  index3 = -1\n",
        "  for result3 in fourth_wrong:\n",
        "    index3 += 1\n",
        "    if result3 == 1 and result3 == first_wrong[index3]:\n",
        "      num_first_fourth_wrong += 1\n",
        "    if result3 == 1 and result3 == second_wrong[index3]:\n",
        "      num_second_fourth_wrong += 1\n",
        "    if result3 == 1 and result3== second_wrong[index3] and result3 == first_wrong[index3]:\n",
        "      num_first_second_fourth_overwrong += 1\n",
        "    if result3 == 1 and result3 == third_wrong[index3]:\n",
        "      num_third_fourth_wrong += 1\n",
        "    if result3 == 1 and result3== third_wrong[index3] and result3 == second_wrong[index3]:\n",
        "      num_second_third_fourth_overwrong += 1  \n",
        "    if result3 == 1 and result3== third_wrong[index3] and result3 == first_wrong[index3]:\n",
        "      num_first_third_fourth_overwrong += 1\n",
        "    if result3 == 1 and result3== third_wrong[index3] and result3 == first_wrong[index3] and result3 == second_wrong[index3]:\n",
        "      num_first_second_third_fourth_overwrong += 1\n",
        "    \n",
        "  num_fourth_else_wrong = sum(fourth_wrong)-num_first_fourth_wrong-num_second_fourth_wrong+num_first_second_fourth_overwrong-num_third_fourth_wrong+num_second_third_fourth_overwrong+num_first_third_fourth_overwrong+num_first_second_third_fourth_overwrong\n",
        "  \n",
        "  return(num_first_wrong,num_first_second_wrong,num_second_else_wrong,num_first_third_wrong,num_second_third_wrong,num_third_else_wrong,num_NET_third_first_wrong,num_first_fourth_wrong,num_second_fourth_wrong,num_third_fourth_wrong,num_fourth_else_wrong)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "268X1y8hD_9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_truth=y_test.reshape(10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpx3MM6GCXtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a,b,c,d,e,f,g,h,i,j,k=progress_count(model1_pred,model2_pred,model3_pred,model4_pred,y_test_truth)\n",
        "print(a,b,c,d,e,f,g,h,i,j,k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUgcPvYj7TSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training_history(results):\n",
        "    # Get the classification accuracy and loss-value\n",
        "    # for the training-set.\n",
        "    acc = results.history['acc']\n",
        "    loss = results.history['loss']\n",
        "\n",
        "    # Get it for the validation-set (we only use the test-set).\n",
        "    try:\n",
        "      val_acc = results.history['val_acc']\n",
        "      val_loss = results.history['val_loss']\n",
        "    except:\n",
        "      pass\n",
        "    # Plot the accuracy and loss-values for the training-set.\n",
        "    plt.plot(acc, linestyle='-', color='b', label='Training Acc.')\n",
        "    plt.plot(loss, 'o', color='b', label='Training Loss')\n",
        "    \n",
        "    # Plot it for the test-set.\n",
        "    try:\n",
        "      plt.plot(val_acc, linestyle='--', color='r', label='Test Acc.')\n",
        "      plt.plot(val_loss, 'o', color='r', label='Test Loss')\n",
        "    except:\n",
        "      pass\n",
        "    # Plot title and legend.\n",
        "    plt.title('Training and Test Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Ensure the plot shows correctly.\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex9ufIemGmQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_error_imgs2(predictions, orig_imgs, real_values):\n",
        "  index = -1\n",
        "  count = 0\n",
        "  wrong_img_indexes = []\n",
        "  wrong_img_list = []\n",
        "  wrong_img_class_list = []\n",
        "  for item in predictions:\n",
        "    index+=1\n",
        "    if item != real_values[index]:\n",
        "      count +=1\n",
        "      wrong_img_indexes.append(index)\n",
        "  print(count)\n",
        "  for index2 in wrong_img_indexes:\n",
        "    wrong_img_list.append(orig_imgs[index2])\n",
        "    wrong_img_class_list.append(real_values[index2][0])\n",
        "      \n",
        "  return wrong_img_indexes, wrong_img_list,wrong_img_class_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLC0_rhsVwVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weight2 = compute_class_weight(class_weight='balanced',\n",
        "                                    classes=np.unique(model1_wrong_img_class),\n",
        "                                    y=model1_wrong_img_class)\n",
        "class_weight2=class_weight2*class_weight2\n",
        "class_weight2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7HY2SQ3r4Mf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint2 = ModelCheckpoint('cnn2_cifar10_finetuned.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
        "\n",
        "'''model2_history = model2.fit_generator(datagen.flow(model1_wrong_imgs, model1_wrong_img_class_cat, batch_size=32),\\\n",
        "                    steps_per_epoch=x_train.shape[0] // 32,epochs=30,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test_cat),callbacks=[LearningRateScheduler(lr_schedule),checkpoint2],class_weight = class_weight2)'''\n",
        "model2_finetune_history = model2.fit_generator(datagen.flow(x_train, y_train_cat, batch_size=64),\\\n",
        "                    steps_per_epoch=x_train.shape[0] // 64,epochs=20,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test_cat),callbacks=[LearningRateScheduler(lr_schedule),checkpoint2])\n",
        "plot_training_history(model2_finetune_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSsSLojwjUGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2=load_model('cnn2_cifar10_finetuned.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wzfxLZ0e5Sx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2_pred_train = performance(model2,x_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s27zAExWjMSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2_pred_test = performance(model2,x_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcTjHZPMVYLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2_pred_wrongimgs = performance(model2,model1_wrong_imgs,model1_wrong_img_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-_XqbNsj42L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1_pred_wrongimgs = performance(model1,model1_wrong_imgs,model1_wrong_img_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Miwc4IIYkJRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1_pred_test = performance(model1,x_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8gGmaAD9Vxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2_wrong_indexes,model2_wrong_imgs,model2_wrong_img_class  = generate_error_imgs2(model2_pred_train,x_train,y_train)\n",
        "model2_wrong_imgs = np.array(model2_wrong_imgs)\n",
        "\n",
        "model2_wrong_img_class = np.array(model2_wrong_img_class)\n",
        "model2_wrong_img_class_cat = np_utils.to_categorical(model2_wrong_img_class,num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bcrhcro0taFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weight3 = compute_class_weight(class_weight='balanced',\n",
        "                                    classes=np.unique(model2_wrong_img_class),\n",
        "                                    y=model2_wrong_img_class)\n",
        "class_weight3=class_weight3*class_weight3\n",
        "class_weight3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1gy3V3CS4WK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weight3 = compute_class_weight(class_weight='balanced',\n",
        "                                    classes=np.unique(res2_wrong_img_class),\n",
        "                                    y=res2_wrong_img_class)\n",
        "class_weight3=class_weight3*class_weight3\n",
        "class_weight3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrv-ySCI9ZyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_training_history(resnet3_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5r95l-B97dW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint3 = ModelCheckpoint('cnn3_cifar10_finetuned.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
        "\n",
        "'''model3_history = model3.fit_generator(datagen.flow(model2_wrong_imgs, model2_wrong_img_class_cat, batch_size=32),\\\n",
        "                    steps_per_epoch=x_train.shape[0] // 32,epochs=30,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test_cat),callbacks=[LearningRateScheduler(lr_schedule),checkpoint3],class_weight = class_weight3)'''\n",
        "model3_finetune_history = model3.fit_generator(datagen.flow(x_train, y_train_cat, batch_size=64),\\\n",
        "                    steps_per_epoch=x_train.shape[0] // 64,epochs=10,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test_cat),callbacks=[LearningRateScheduler(lr_schedule),checkpoint3])\n",
        "plot_training_history(model3_finetune_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNcrWpRV84f3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_training_history(model3_finetune_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ALgfJeQQLOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3_pred_wrongimgs = performance(model3,model2_wrong_imgs, model2_wrong_img_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP_7szoclaPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3_pred_test = performance(model3,x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_2bwUa8a3LK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3_pred_train = performance(model3,x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vthcK4ima72X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3_wrong_indexes,model3_wrong_imgs,model3_wrong_img_class  = generate_error_imgs2(model3_pred_train,x_train,y_train)\n",
        "model3_wrong_imgs = np.array(model3_wrong_imgs)\n",
        "\n",
        "model3_wrong_img_class = np.array(model3_wrong_img_class)\n",
        "model3_wrong_img_class_cat = np_utils.to_categorical(model3_wrong_img_class,num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62lOCPTSFxSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weight4 = compute_class_weight(class_weight='balanced',\n",
        "                                    classes=np.unique(model3_wrong_img_class),\n",
        "                                    y=model3_wrong_img_class)\n",
        "class_weight4=class_weight4*class_weight4\n",
        "class_weight4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vglmaBvqFaOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint1_pt2 = ModelCheckpoint('cnn1_cifar10_refinetuned.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
        "\n",
        "'''model1_history = model1.fit_generator(datagen.flow(model3_wrong_imgs, model3_wrong_img_class_cat, batch_size=32),\\\n",
        "                    steps_per_epoch=x_train.shape[0] // 32,epochs=20,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test_cat),callbacks=[LearningRateScheduler(lr_schedule),checkpoint1_pt2],class_weight = class_weight4)'''\n",
        "model1_refinetune_history = model1.fit_generator(datagen.flow(x_train, y_train_cat, batch_size=64),\\\n",
        "                    steps_per_epoch=x_train.shape[0] // 64,epochs=10,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test_cat),callbacks=[LearningRateScheduler(lr_schedule),checkpoint1_pt2])\n",
        "plot_training_history(model1_refinetune_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwno03-DLWao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1_refinetuned_pred_wrong1 = performance(model1,model1_wrong_imgs,model1_wrong_img_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reXkQeF4MhdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1_refinetuned_pred_wrong3 = performance(model1,model3_wrong_imgs,model3_wrong_img_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHVE23bwPCUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1_pred_test = performance(model1,x_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLsrmfXvgzcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model1_pred_vals = model1.predict(x_train)\n",
        "#model1_pred_vals = model2.predict(x_train)\n",
        "#model3_pred_vals = model3.predict(x_train)\n",
        "model4_pred_vals = model4.predict(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzGXyavgnl9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''model1_pred_test_vals = model1.predict(x_test)\n",
        "model2_pred_test_vals = model2.predict(x_test)\n",
        "model3_pred_test_vals = model3.predict(x_test)'''\n",
        "model4_pred_test_vals = model4.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImRFAQP6g3k_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1_pred_vals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjM_i8r0PI3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1_pred_vals = performance(model1,x_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NSy25zWHaxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1_pred_vals_0 = [i[0] for i in model1_pred_vals]\n",
        "model1_pred_vals_1 = [i[1] for i in model1_pred_vals]\n",
        "model1_pred_vals_2 = [i[2] for i in model1_pred_vals]\n",
        "model1_pred_vals_3 = [i[3] for i in model1_pred_vals]\n",
        "model1_pred_vals_4 = [i[4] for i in model1_pred_vals]\n",
        "model1_pred_vals_5 = [i[5] for i in model1_pred_vals]\n",
        "model1_pred_vals_6 = [i[6] for i in model1_pred_vals]\n",
        "model1_pred_vals_7 = [i[7] for i in model1_pred_vals]\n",
        "model1_pred_vals_8 = [i[8] for i in model1_pred_vals]\n",
        "model1_pred_vals_9 = [i[9] for i in model1_pred_vals]\n",
        "\n",
        "reshaped_model2_pred_vals_0 = [i[0] for i in model2_pred_vals]\n",
        "reshaped_model2_pred_vals_1 = [i[1] for i in model2_pred_vals]\n",
        "reshaped_model2_pred_vals_2 = [i[2] for i in model2_pred_vals]\n",
        "reshaped_model2_pred_vals_3 = [i[3] for i in model2_pred_vals]\n",
        "reshaped_model2_pred_vals_4 = [i[4] for i in model2_pred_vals]\n",
        "reshaped_model2_pred_vals_5 = [i[5] for i in model2_pred_vals]\n",
        "reshaped_model2_pred_vals_6 = [i[6] for i in model2_pred_vals]\n",
        "reshaped_model2_pred_vals_7 = [i[7] for i in model2_pred_vals]\n",
        "reshaped_model2_pred_vals_8 = [i[8] for i in model2_pred_vals]\n",
        "reshaped_model2_pred_vals_9 = [i[9] for i in model2_pred_vals]\n",
        "\n",
        "reshaped_model3_pred_vals_0 = [i[0] for i in model3_pred_vals]\n",
        "reshaped_model3_pred_vals_1 = [i[1] for i in model3_pred_vals]\n",
        "reshaped_model3_pred_vals_2 = [i[2] for i in model3_pred_vals]\n",
        "reshaped_model3_pred_vals_3 = [i[3] for i in model3_pred_vals]\n",
        "reshaped_model3_pred_vals_4 = [i[4] for i in model3_pred_vals]\n",
        "reshaped_model3_pred_vals_5 = [i[5] for i in model3_pred_vals]\n",
        "reshaped_model3_pred_vals_6 = [i[6] for i in model3_pred_vals]\n",
        "reshaped_model3_pred_vals_7 = [i[7] for i in model3_pred_vals]\n",
        "reshaped_model3_pred_vals_8 = [i[8] for i in model3_pred_vals]\n",
        "reshaped_model3_pred_vals_9 = [i[9] for i in model3_pred_vals]\n",
        "\n",
        "reshaped_model4_pred_vals_0 = [i[0] for i in model4_pred_vals]\n",
        "reshaped_model4_pred_vals_1 = [i[1] for i in model4_pred_vals]\n",
        "reshaped_model4_pred_vals_2 = [i[2] for i in model4_pred_vals]\n",
        "reshaped_model4_pred_vals_3 = [i[3] for i in model4_pred_vals]\n",
        "reshaped_model4_pred_vals_4 = [i[4] for i in model4_pred_vals]\n",
        "reshaped_model4_pred_vals_5 = [i[5] for i in model4_pred_vals]\n",
        "reshaped_model4_pred_vals_6 = [i[6] for i in model4_pred_vals]\n",
        "reshaped_model4_pred_vals_7 = [i[7] for i in model4_pred_vals]\n",
        "reshaped_model4_pred_vals_8 = [i[8] for i in model4_pred_vals]\n",
        "reshaped_model4_pred_vals_9 = [i[9] for i in model4_pred_vals]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlL-mkYUsjru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model1_pred_train_vals2_0 = [i[0] for i in model1_pred_train_vals2]\n",
        "model1_pred_train_vals2_1 = [i[1] for i in model1_pred_train_vals2]\n",
        "model1_pred_train_vals2_2 = [i[2] for i in model1_pred_train_vals2]\n",
        "model1_pred_train_vals2_3 = [i[3] for i in model1_pred_train_vals2]\n",
        "model1_pred_train_vals2_4 = [i[4] for i in model1_pred_train_vals2]\n",
        "model1_pred_train_vals2_5 = [i[5] for i in model1_pred_train_vals2]\n",
        "model1_pred_train_vals2_6 = [i[6] for i in model1_pred_train_vals2]\n",
        "model1_pred_train_vals2_7 = [i[7] for i in model1_pred_train_vals2]\n",
        "model1_pred_train_vals2_8 = [i[8] for i in model1_pred_train_vals2]\n",
        "model1_pred_train_vals2_9 = [i[9] for i in model1_pred_train_vals2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz-OLfT5smix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1_pred_test_vals2_0 = [i[0] for i in model1_pred_test_vals2]\n",
        "model1_pred_test_vals2_1 = [i[1] for i in model1_pred_test_vals2]\n",
        "model1_pred_test_vals2_2 = [i[2] for i in model1_pred_test_vals2]\n",
        "model1_pred_test_vals2_3 = [i[3] for i in model1_pred_test_vals2]\n",
        "model1_pred_test_vals2_4 = [i[4] for i in model1_pred_test_vals2]\n",
        "model1_pred_test_vals2_5 = [i[5] for i in model1_pred_test_vals2]\n",
        "model1_pred_test_vals2_6 = [i[6] for i in model1_pred_test_vals2]\n",
        "model1_pred_test_vals2_7 = [i[7] for i in model1_pred_test_vals2]\n",
        "model1_pred_test_vals2_8 = [i[8] for i in model1_pred_test_vals2]\n",
        "model1_pred_test_vals2_9 = [i[9] for i in model1_pred_test_vals2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN1SKJIun4Me",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1_pred_test_vals_0 = [i[0] for i in model1_pred_test_vals]\n",
        "model1_pred_test_vals_1 = [i[1] for i in model1_pred_test_vals]\n",
        "model1_pred_test_vals_2 = [i[2] for i in model1_pred_test_vals]\n",
        "model1_pred_test_vals_3 = [i[3] for i in model1_pred_test_vals]\n",
        "model1_pred_test_vals_4 = [i[4] for i in model1_pred_test_vals]\n",
        "model1_pred_test_vals_5 = [i[5] for i in model1_pred_test_vals]\n",
        "model1_pred_test_vals_6 = [i[6] for i in model1_pred_test_vals]\n",
        "model1_pred_test_vals_7 = [i[7] for i in model1_pred_test_vals]\n",
        "model1_pred_test_vals_8 = [i[8] for i in model1_pred_test_vals]\n",
        "model1_pred_test_vals_9 = [i[9] for i in model1_pred_test_vals]\n",
        "\n",
        "reshaped_model2_pred_test_vals_0 = [i[0] for i in model2_pred_test_vals]\n",
        "reshaped_model2_pred_test_vals_1 = [i[1] for i in model2_pred_test_vals]\n",
        "reshaped_model2_pred_test_vals_2 = [i[2] for i in model2_pred_test_vals]\n",
        "reshaped_model2_pred_test_vals_3 = [i[3] for i in model2_pred_test_vals]\n",
        "reshaped_model2_pred_test_vals_4 = [i[4] for i in model2_pred_test_vals]\n",
        "reshaped_model2_pred_test_vals_5 = [i[5] for i in model2_pred_test_vals]\n",
        "reshaped_model2_pred_test_vals_6 = [i[6] for i in model2_pred_test_vals]\n",
        "reshaped_model2_pred_test_vals_7 = [i[7] for i in model2_pred_test_vals]\n",
        "reshaped_model2_pred_test_vals_8 = [i[8] for i in model2_pred_test_vals]\n",
        "reshaped_model2_pred_test_vals_9 = [i[9] for i in model2_pred_test_vals]\n",
        "\n",
        "reshaped_model3_pred_test_vals_0 = [i[0] for i in model3_pred_test_vals]\n",
        "reshaped_model3_pred_test_vals_1 = [i[1] for i in model3_pred_test_vals]\n",
        "reshaped_model3_pred_test_vals_2 = [i[2] for i in model3_pred_test_vals]\n",
        "reshaped_model3_pred_test_vals_3 = [i[3] for i in model3_pred_test_vals]\n",
        "reshaped_model3_pred_test_vals_4 = [i[4] for i in model3_pred_test_vals]\n",
        "reshaped_model3_pred_test_vals_5 = [i[5] for i in model3_pred_test_vals]\n",
        "reshaped_model3_pred_test_vals_6 = [i[6] for i in model3_pred_test_vals]\n",
        "reshaped_model3_pred_test_vals_7 = [i[7] for i in model3_pred_test_vals]\n",
        "reshaped_model3_pred_test_vals_8 = [i[8] for i in model3_pred_test_vals]\n",
        "reshaped_model3_pred_test_vals_9 = [i[9] for i in model3_pred_test_vals]\n",
        "\n",
        "reshaped_model4_pred_test_vals_0 = [i[0] for i in model4_pred_test_vals]\n",
        "reshaped_model4_pred_test_vals_1 = [i[1] for i in model4_pred_test_vals]\n",
        "reshaped_model4_pred_test_vals_2 = [i[2] for i in model4_pred_test_vals]\n",
        "reshaped_model4_pred_test_vals_3 = [i[3] for i in model4_pred_test_vals]\n",
        "reshaped_model4_pred_test_vals_4 = [i[4] for i in model4_pred_test_vals]\n",
        "reshaped_model4_pred_test_vals_5 = [i[5] for i in model4_pred_test_vals]\n",
        "reshaped_model4_pred_test_vals_6 = [i[6] for i in model4_pred_test_vals]\n",
        "reshaped_model4_pred_test_vals_7 = [i[7] for i in model4_pred_test_vals]\n",
        "reshaped_model4_pred_test_vals_8 = [i[8] for i in model4_pred_test_vals]\n",
        "reshaped_model4_pred_test_vals_9 = [i[9] for i in model4_pred_test_vals]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex3E46n4of0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test ANN\n",
        "import pandas as pd\n",
        "dataset4 = pd.DataFrame({'first0': model1_pred_test_vals_0,\n",
        "                        'first1': model1_pred_test_vals_1,\n",
        "                        'first2': model1_pred_test_vals_2,\n",
        "                        'first3': model1_pred_test_vals_3,\n",
        "                        'first4': model1_pred_test_vals_4,\n",
        "                        'first5': model1_pred_test_vals_5,\n",
        "                        'first6': model1_pred_test_vals_6,\n",
        "                        'first7': model1_pred_test_vals_7,\n",
        "                        'first8': model1_pred_test_vals_8,\n",
        "                        'first9': model1_pred_test_vals_9,\n",
        "                        'inverse0': reshaped_model2_pred_test_vals_0,\n",
        "                        'inverse1': reshaped_model2_pred_test_vals_1,\n",
        "                        'inverse2': reshaped_model2_pred_test_vals_2,\n",
        "                        'inverse3': reshaped_model2_pred_test_vals_3,\n",
        "                        'inverse4': reshaped_model2_pred_test_vals_4,\n",
        "                        'inverse5': reshaped_model2_pred_test_vals_5,\n",
        "                        'inverse6': reshaped_model2_pred_test_vals_6,\n",
        "                        'inverse7': reshaped_model2_pred_test_vals_7,\n",
        "                        'inverse8': reshaped_model2_pred_test_vals_8,\n",
        "                        'inverse9': reshaped_model2_pred_test_vals_9,\n",
        "                        'invverse0': reshaped_model3_pred_test_vals_0,\n",
        "                        'invverse1': reshaped_model3_pred_test_vals_1,\n",
        "                        'invverse2': reshaped_model3_pred_test_vals_2,\n",
        "                        'invverse3': reshaped_model3_pred_test_vals_3,\n",
        "                        'invverse4': reshaped_model3_pred_test_vals_4,\n",
        "                        'invverse5': reshaped_model3_pred_test_vals_5,\n",
        "                        'invverse6': reshaped_model3_pred_test_vals_6,\n",
        "                        'invverse7': reshaped_model3_pred_test_vals_7,\n",
        "                        'invverse8': reshaped_model3_pred_test_vals_8,\n",
        "                        'invverse9': reshaped_model3_pred_test_vals_9,\n",
        "                        'invvverse0': reshaped_model4_pred_test_vals_0,\n",
        "                        'invvverse1': reshaped_model4_pred_test_vals_1,\n",
        "                        'invvverse2': reshaped_model4_pred_test_vals_2,\n",
        "                        'invvverse3': reshaped_model4_pred_test_vals_3,\n",
        "                        'invvverse4': reshaped_model4_pred_test_vals_4,\n",
        "                        'invvverse5': reshaped_model4_pred_test_vals_5,\n",
        "                        'invvverse6': reshaped_model4_pred_test_vals_6,\n",
        "                        'invvverse7': reshaped_model4_pred_test_vals_7,\n",
        "                        'invvverse8': reshaped_model4_pred_test_vals_8,\n",
        "                        'invvverse9': reshaped_model4_pred_test_vals_9,\n",
        "                        'correct':y_test_reshape}, \n",
        "                       index=np.arange(len(y_test_reshape)),columns=['first0',\n",
        "                                                                   'first1',\n",
        "                                                                   'first2',\n",
        "                                                                   'first3',\n",
        "                                                                   'first4',\n",
        "                                                                   'first5',\n",
        "                                                                   'first6',\n",
        "                                                                   'first7',\n",
        "                                                                   'first8',\n",
        "                                                                   'first9',\n",
        "                                                                   'inverse0',\n",
        "                                                                   'inverse1',\n",
        "                                                                   'inverse2',\n",
        "                                                                   'inverse3',\n",
        "                                                                   'inverse4',\n",
        "                                                                   'inverse5',\n",
        "                                                                   'inverse6',\n",
        "                                                                   'inverse7',\n",
        "                                                                   'inverse8',\n",
        "                                                                   'inverse9',\n",
        "                                                                   'invverse0',\n",
        "                                                                   'invverse1',\n",
        "                                                                   'invverse2',\n",
        "                                                                   'invverse3',\n",
        "                                                                   'invverse4',\n",
        "                                                                   'invverse5',\n",
        "                                                                   'invverse6',\n",
        "                                                                   'invverse7',\n",
        "                                                                   'invverse8',\n",
        "                                                                   'invverse9',\n",
        "                                                                   'invvverse0',\n",
        "                                                                   'invvverse1',\n",
        "                                                                   'invvverse2',\n",
        "                                                                   'invvverse3',\n",
        "                                                                   'invvverse4',\n",
        "                                                                   'invvverse5',\n",
        "                                                                   'invvverse6',\n",
        "                                                                   'invvverse7',\n",
        "                                                                   'invvverse8',\n",
        "                                                                   'invvverse9',\n",
        "                                                                   'correct'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbkm-BvRjVM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_reshape=y_train.reshape(len(y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9X0nKcniMnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "dataset2_train = pd.DataFrame({'first0': model1_pred_vals_0,\n",
        "                        'first1': model1_pred_vals_1,\n",
        "                        'first2': model1_pred_vals_2,\n",
        "                        'first3': model1_pred_vals_3,\n",
        "                        'first4': model1_pred_vals_4,\n",
        "                        'first5': model1_pred_vals_5,\n",
        "                        'first6': model1_pred_vals_6,\n",
        "                        'first7': model1_pred_vals_7,\n",
        "                        'first8': model1_pred_vals_8,\n",
        "                        'first9': model1_pred_vals_9,\n",
        "                        'inverse0': reshaped_model2_pred_vals_0,\n",
        "                        'inverse1': reshaped_model2_pred_vals_1,\n",
        "                        'inverse2': reshaped_model2_pred_vals_2,\n",
        "                        'inverse3': reshaped_model2_pred_vals_3,\n",
        "                        'inverse4': reshaped_model2_pred_vals_4,\n",
        "                        'inverse5': reshaped_model2_pred_vals_5,\n",
        "                        'inverse6': reshaped_model2_pred_vals_6,\n",
        "                        'inverse7': reshaped_model2_pred_vals_7,\n",
        "                        'inverse8': reshaped_model2_pred_vals_8,\n",
        "                        'inverse9': reshaped_model2_pred_vals_9,\n",
        "                        'invverse0': reshaped_model3_pred_vals_0,\n",
        "                        'invverse1': reshaped_model3_pred_vals_1,\n",
        "                        'invverse2': reshaped_model3_pred_vals_2,\n",
        "                        'invverse3': reshaped_model3_pred_vals_3,\n",
        "                        'invverse4': reshaped_model3_pred_vals_4,\n",
        "                        'invverse5': reshaped_model3_pred_vals_5,\n",
        "                        'invverse6': reshaped_model3_pred_vals_6,\n",
        "                        'invverse7': reshaped_model3_pred_vals_7,\n",
        "                        'invverse8': reshaped_model3_pred_vals_8,\n",
        "                        'invverse9': reshaped_model3_pred_vals_9,\n",
        "                        'invvverse0': reshaped_model4_pred_vals_0,\n",
        "                        'invvverse1': reshaped_model4_pred_vals_1,\n",
        "                        'invvverse2': reshaped_model4_pred_vals_2,\n",
        "                        'invvverse3': reshaped_model4_pred_vals_3,\n",
        "                        'invvverse4': reshaped_model4_pred_vals_4,\n",
        "                        'invvverse5': reshaped_model4_pred_vals_5,\n",
        "                        'invvverse6': reshaped_model4_pred_vals_6,\n",
        "                        'invvverse7': reshaped_model4_pred_vals_7,\n",
        "                        'invvverse8': reshaped_model4_pred_vals_8,\n",
        "                        'invvverse9': reshaped_model4_pred_vals_9,\n",
        "                        'correct':y_train_reshape}, \n",
        "                       index=np.arange(len(y_train_reshape)),columns=['first0',\n",
        "                                                                   'first1',\n",
        "                                                                   'first2',\n",
        "                                                                   'first3',\n",
        "                                                                   'first4',\n",
        "                                                                   'first5',\n",
        "                                                                   'first6',\n",
        "                                                                   'first7',\n",
        "                                                                   'first8',\n",
        "                                                                   'first9',\n",
        "                                                                   'inverse0',\n",
        "                                                                   'inverse1',\n",
        "                                                                   'inverse2',\n",
        "                                                                   'inverse3',\n",
        "                                                                   'inverse4',\n",
        "                                                                   'inverse5',\n",
        "                                                                   'inverse6',\n",
        "                                                                   'inverse7',\n",
        "                                                                   'inverse8',\n",
        "                                                                   'inverse9',\n",
        "                                                                   'invverse0',\n",
        "                                                                   'invverse1',\n",
        "                                                                   'invverse2',\n",
        "                                                                   'invverse3',\n",
        "                                                                   'invverse4',\n",
        "                                                                   'invverse5',\n",
        "                                                                   'invverse6',\n",
        "                                                                   'invverse7',\n",
        "                                                                   'invverse8',\n",
        "                                                                   'invverse9',\n",
        "                                                                   'invvverse0',\n",
        "                                                                   'invvverse1',\n",
        "                                                                   'invvverse2',\n",
        "                                                                   'invvverse3',\n",
        "                                                                   'invvverse4',\n",
        "                                                                   'invvverse5',\n",
        "                                                                   'invvverse6',\n",
        "                                                                   'invvverse7',\n",
        "                                                                   'invvverse8',\n",
        "                                                                   'invvverse9',\n",
        "                                                                   'correct'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mykw1zZRpHDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_vals = dataset4.iloc[:, :40].values\n",
        "y_test_vals = dataset4.iloc[:, 40].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZX1D72pAm1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_vals = dataset4.iloc[:, :30].values\n",
        "y_test_vals = dataset4.iloc[:, 40].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B7Fx16PndVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ann_predict3_test = ann_model3.predict(X_test_vals)\n",
        "rounded_real_train = []\n",
        "for item in ann_predict3_test:\n",
        "  maxx = max(item)\n",
        "  rounded_real_train.append(np.where(item==maxx)[0][0])\n",
        "\n",
        "print(classification_report(y_test_vals, rounded_real_train))  \n",
        "print(confusion_matrix(y_test_vals,rounded_real_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpUoxtWhnarw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X3 = dataset2_train.iloc[:, :30].values\n",
        "y3 = dataset2_train.iloc[:, 40].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5PTe_kHjqTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = dataset2_train.iloc[:, :40].values\n",
        "y = dataset2_train.iloc[:, 40].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFJdCbr5j02A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.2, random_state=91)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBU344Vz5m2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train3_cat = np_utils.to_categorical(y_train3,10)\n",
        "y_test3_cat = np_utils.to_categorical(y_test3,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWK6X0Tzj7QN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates ann_model2- all training images\n",
        "from keras.optimizers import Adam\n",
        "weight_decay = 1e-4\n",
        "\n",
        "ann_model3 = Sequential()\n",
        "\n",
        "ann_model3.add(Dense(30, input_dim=30, activation='relu'))\n",
        "ann_model3.add(Dense(512, activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "ann_model3.add(Dropout(0.4))\n",
        "\n",
        "ann_model3.add(Dense(512, activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "ann_model3.add(Dropout(0.4))\n",
        "\n",
        "# Last layer simple sigmoid function to output 0 or 1 (our label)\n",
        "ann_model3.add(Dense(10, activation='softmax'))\n",
        "\n",
        "ann_model3.compile(Adam(lr=0.01),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "checkpoint_ann = ModelCheckpoint('cifar_ann_three_models_vals_refinetuned.h5', verbose=1, monitor='loss',save_best_only=True, mode='auto')  \n",
        "\n",
        "ann_model3_results = ann_model3.fit(X_train3,y_train3_cat,epochs=20,  callbacks=[checkpoint_ann], verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6qU_RmHlrL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ann_model3=load_model('cifar_ann_three_models_vals_refinetuned.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LozgejCVl6aT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ann_predict_test = ann_model3.predict(X_test3)\n",
        "rounded_real_train = []\n",
        "for item in ann_predict_test:\n",
        "  maxx = max(item)\n",
        "  rounded_real_train.append(np.where(item==maxx)[0][0])\n",
        "\n",
        "print(classification_report(y_test3, rounded_real_train))  \n",
        "print(confusion_matrix(y_test3,rounded_real_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPZO5kt1a76f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint4 = ModelCheckpoint('cnn4_cifar10_finetuned.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
        "\n",
        "'''model4_history = model4.fit_generator(datagen.flow(model3_wrong_imgs, model3_wrong_img_class_cat, batch_size=32),\\\n",
        "                    steps_per_epoch=x_train.shape[0] // 32,epochs=20,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test_cat),callbacks=[LearningRateScheduler(lr_schedule),checkpoint3],class_weight = class_weight4)'''\n",
        "model4_finetune_history = model4.fit_generator(datagen.flow(x_train, y_train_cat, batch_size=64),\\\n",
        "                    steps_per_epoch=x_train.shape[0] // 64,epochs=10,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test_cat),callbacks=[LearningRateScheduler(lr_schedule),checkpoint4])\n",
        "plot_training_history(model4_finetune_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftk3CvFI7a5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model4_pred_wrongimgs = performance(model4,model3_wrong_imgs, model3_wrong_img_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEwwPl4ABnPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model4_pred_train = performance(model4,x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJWGW3D8Bs3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model4_pred_test = performance(model4,x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxK7oRs-eLbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_gather: Test ann on firsttest\n",
        "\n",
        "model1_predtest=np.array(model1_pred_test)\n",
        "model2_predtest=np.array(model2_pred_test)\n",
        "model3_predtest=np.array(model3_pred_test)\n",
        "#model4_predtest=np.array(model4_pred_test)\n",
        "\n",
        "\n",
        "model1_predtest_reshape = model1_predtest.reshape(len(model1_predtest))\n",
        "model2_predtest_reshape = model2_predtest.reshape(len(model2_predtest))\n",
        "model3_predtest_reshape = model3_predtest.reshape(len(model3_predtest))\n",
        "#model4_predtest_reshape = model4_predtest.reshape(len(model4_predtest))\n",
        "\n",
        "y_test_reshape = y_test.reshape(len(y_test))\n",
        "\n",
        "dataset3_test = pd.DataFrame({'first': model1_predtest_reshape, 'inverse': model2_predtest_reshape,'third':model3_predtest_reshape,'correct':y_test_reshape}, index=np.arange(len(model3_predtest_reshape)),columns=['first', 'inverse','third','correct'])\n",
        "#dataset_test4 = pd.DataFrame({'first': model1_predtest_reshape, 'second': model2_predtest_reshape, 'third':model3_predtest_reshape,'fourth':model4_predtest_reshape,'correct':y_test_reshape}, index=np.arange(len(model4_predtest_reshape)),columns=['first', 'second','third','fourth','correct'])\n",
        "\n",
        "\n",
        "Meta3_X_test = dataset3_test.iloc[:,0:3]\n",
        "Meta3_y_test = dataset3_test.iloc[:,3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-yZS7CgnuCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "# data_gather: Train ann on both model's predictions on the original training data\n",
        "model1_predtrain=np.array(model1_pred_vals)\n",
        "model2_predtrain=np.array(model2_pred_vals)\n",
        "model3_predtrain=np.array(model3_pred_train)\n",
        "#model4_predtrain=np.array(model4_pred_train)\n",
        "\n",
        "\n",
        "model1_predtrain_reshape = model1_predtrain.reshape(len(model1_predtrain))\n",
        "model2_predtrain_reshape = model2_predtrain.reshape(len(model2_predtrain))\n",
        "model3_predtrain_reshape = model3_predtrain.reshape(len(model3_predtrain))\n",
        "#model4_predtrain_reshape = model4_predtrain.reshape(len(model4_predtrain))\n",
        "\n",
        "y_train_reshape = y_train.reshape(len(y_train))\n",
        "\n",
        "dataset = pd.DataFrame({'first': model1_predtrain_reshape, 'inverse': model2_predtrain_reshape, 'third':model3_predtrain_reshape,'correct':y_train_reshape}, index=np.arange(len(model1_predtrain_reshape)),columns=['first', 'inverse','third','correct'])\n",
        "#dataset4 = pd.DataFrame({'first': model1_predtrain_reshape, 'inverse': model3_predtrain_reshape, 'third':model2_predtrain_reshape,'fourth':model4_predtrain_reshape,'correct':y_train_reshape}, index=np.arange(len(model1_predtrain_reshape)),columns=['first', 'inverse','third','fourth','correct'])\n",
        "\n",
        "Meta3_X = dataset.iloc[:,0:3]\n",
        "Meta3_y = dataset.iloc[:,3]\n",
        "\n",
        "'''Meta2_X = dataset.iloc[:,0:2]\n",
        "Meta2_y = dataset.iloc[:,3]\n",
        "\n",
        "Meta4_X=dataset4.iloc[:,0:4]\n",
        "Meta4_y=dataset4.iloc[:,4]'''\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "Meta3_X_train,Meta3_X_test, Meta3_y_train, Meta3_y_test = train_test_split(Meta3_X, Meta3_y, test_size=0.3, random_state=91)\n",
        "#Meta2_X_train,Meta2_X_test, Meta2_y_train, Meta2_y_test = train_test_split(Meta2_X, Meta2_y, test_size=0.3, random_state=91)\n",
        "#Meta4_X_train,Meta4_X_test, Meta4_y_train, Meta4_y_test = train_test_split(Meta4_X, Meta4_y, test_size=0.3, random_state=91)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmJwSke5oWaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Meta3_y_train_cat = np_utils.to_categorical(Meta3_y_train,10)\n",
        "Meta3_y_test_cat = np_utils.to_categorical(Meta3_y_test,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2PcjHMQXFw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ann_predict_test = ann_model3.predict(Meta3_X_test)\n",
        "rounded_real_train = []\n",
        "for item in ann_predict_test:\n",
        "  maxx = max(item)\n",
        "  rounded_real_train.append(np.where(item==maxx)[0][0])\n",
        "\n",
        "print(classification_report(Meta3_y_test, rounded_real_train))  \n",
        "print(confusion_matrix(Meta3_y_test,rounded_real_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "docsrwXsPTKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates ann_model2- all training images\n",
        "from keras.optimizers import Adam\n",
        "ann_model3 = Sequential()\n",
        "\n",
        "ann_model3.add(Dense(3, input_dim=3, activation='relu'))\n",
        "ann_model3.add(Dense(256, activation='relu'))\n",
        "ann_model3.add(Dropout(0.3))\n",
        "\n",
        "ann_model3.add(Dense(256, activation='relu'))\n",
        "ann_model3.add(Dropout(0.3))\n",
        "\n",
        "# Last layer simple sigmoid function to output 0 or 1 (our label)\n",
        "ann_model3.add(Dense(10, activation='softmax'))\n",
        "\n",
        "ann_model3.compile(Adam(lr=0.01),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "checkpoint_ann = ModelCheckpoint('cifar_ann_three_models.h5', verbose=1, monitor='loss',save_best_only=True, mode='auto')  \n",
        "\n",
        "ann_model3_results = ann_model3.fit(Meta3_X_train,Meta3_y_train_cat,epochs=15,  callbacks=[checkpoint_ann], verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi1z-0zRRO6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ann_model3 = load_model('cifar_ann_three_models.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIAkAZV4lMtZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates ann_model2- all training images\n",
        "from keras.optimizers import Adam\n",
        "ann_model = Sequential()\n",
        "\n",
        "ann_model.add(Dense(3, input_dim=3, activation='relu'))\n",
        "ann_model.add(Dense(256, activation='relu'))\n",
        "ann_model.add(Dropout(0.3))\n",
        "\n",
        "ann_model.add(Dense(256, activation='relu'))\n",
        "ann_model.add(Dropout(0.3))\n",
        "\n",
        "# Last layer simple sigmoid function to output 0 or 1 (our label)\n",
        "ann_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "ann_model.compile(Adam(lr=0.01),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "checkpoint_ann = ModelCheckpoint('cifar_ann_three_models.h5', verbose=1, monitor='loss',save_best_only=True, mode='auto')  \n",
        "\n",
        "ann_model_results = ann_model.fit(X_train,y_train_cat,epochs=15,  callbacks=[checkpoint_ann], verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwZHdenhqE0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ann_predict3_test = ann_model3.predict(Meta3_X_test)\n",
        "rounded_real_train = []\n",
        "for item in ann_predict3_test:\n",
        "  maxx = max(item)\n",
        "  rounded_real_train.append(np.where(item==maxx)[0][0])\n",
        "\n",
        "print(classification_report(Meta3_y_test, rounded_real_train))  \n",
        "print(confusion_matrix(Meta3_y_test,rounded_real_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77JcxFrt1Nen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predictions4(res1,res2,res3,res4):\n",
        "  final_predictions = []\n",
        "  for item in range(len(res1)):\n",
        "    temp_list = []\n",
        "    temp_list.append([res1[item],res2[item],res3[item],res4[item]])\n",
        "    final_predictions.append(max(temp_list[0], key=temp_list[0].count))\n",
        "  return final_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvq4wfOG3EI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meta_test_predictions = predictions4(model1_pred_test, model2_pred_test, model3_pred_test,model4_pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_9Jufn_3JYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_test, meta_test_predictions))  \n",
        "print(confusion_matrix(y_test,meta_test_predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JUJPNG7t80C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predictions(res1,res2,res3):\n",
        "  final_predictions = []\n",
        "  for item in range(len(res1)):\n",
        "    if res1[item] == res2[item]:\n",
        "      final_predictions.append(res1[item])\n",
        "    elif res1[item] == res3[item]:\n",
        "      final_predictions.append(res1[item])\n",
        "    elif res2[item] == res3[item]:\n",
        "      final_predictions.append(res2[item])\n",
        "    else:\n",
        "      final_predictions.append(res2[item])\n",
        "  return final_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsQqMlSAuaSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meta_test_predictions = predictions(model1_pred_test, model2_pred_test, model3_pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_27gDC4u4QEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_test, meta_test_predictions))  \n",
        "print(confusion_matrix(y_test,meta_test_predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT8skyFne0iT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a,b,c,d,e,f,g=progress_count(model1_pred_test, model2_pred_test, model3_pred_test,y_test_truth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew81L4fvfCBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(a,b,c,d,e,f,g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8vzFH_ICbDf",
        "colab_type": "text"
      },
      "source": [
        "# Section 2 - Binary Machine Learning Classification\n",
        "\n",
        "This section tested the architecture against a \"Will it Rain?\" binary dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-_NYuvFC4N7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read dataset\n",
        "import pandas as pd\n",
        "data = pd.read_csv('weatherAUS.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eroRyR0eC7X8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cut out irrelevant features\n",
        "d1 = data.iloc[:,2:21]\n",
        "d1.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpucpq7xC7kE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cut out irrelevant features\n",
        "del d1['WindGustDir']\n",
        "del d1['WindDir9am']\n",
        "del d1['WindDir3pm']\n",
        "d1.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-bamdmIC7uG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#replace empty values\n",
        "d1.fillna(0, inplace = True)\n",
        "d1.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2agjU-wC722",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get y-values and quantify values\n",
        "dy = data.iloc[:,-1]\n",
        "dy.replace(('Yes', 'No'), (1, 0), inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWM7Mr4zC7-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(d1, dy, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNP7D8vOC8Gh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scale data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NtWDl-GC8Nv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBRoKuHnC8Ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create First Model\n",
        "# Initialising the ANN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu', input_dim = 16))\n",
        "\n",
        "classifier.add(Dropout(0.5))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "# Adding the output layer\n",
        "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "\n",
        "# Compiling the ANN\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "classifier.fit(X_train_scaled, y_train, batch_size = 10, epochs = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hri8IbJiC8c_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define incorrect image function\n",
        "def generate_error_imgs2(predictions, orig_imgs, real_values):\n",
        "  index = -1\n",
        "  count = 0\n",
        "  wrong_img_indexes = []\n",
        "  wrong_img_list = []\n",
        "  wrong_img_class_list = []\n",
        "  for item in predictions:\n",
        "    index+=1\n",
        "    if item != real_values[index]:\n",
        "      count +=1\n",
        "      wrong_img_indexes.append(index)\n",
        "  print(count)\n",
        "  for index2 in wrong_img_indexes:\n",
        "    wrong_img_list.append(orig_imgs[index2])\n",
        "    wrong_img_class_list.append(real_values[index2])\n",
        "      \n",
        "  return wrong_img_indexes, wrong_img_list,wrong_img_class_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4pR035xC8jT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scale test data\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6WNaqY5D8eN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#measure accuracy on test data\n",
        "y_pred = classifier.predict(X_test_scaled)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNb0syAdD8m2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#measure accuracy on train data\n",
        "y_pred = classifier.predict(X_train_scaled)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(accuracy_score(y_train, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuTjMUwzD8tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generate error images\n",
        "wrong_index, wrong_x, wrong_y = generate_error_imgs2(y_pred,X_train_scaled, np.array(y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-3PD6NDD81I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert to arrays\n",
        "wrong_x = np.array(wrong_x)\n",
        "wrong_y = np.array(wrong_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjl8myWQD86X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create Second Model\n",
        "# Initialising the ANN\n",
        "classifier2 = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier2.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu', input_dim = 16))\n",
        "\n",
        "classifier2.add(Dropout(0.5))\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier2.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "# Adding the output layer\n",
        "classifier2.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "\n",
        "# Compiling the ANN\n",
        "classifier2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "classifier2.fit(wrong_x, wrong_y, batch_size = 10, epochs = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8exBl4T9D8-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fine-tune on original data\n",
        "classifier2.fit(X_train_scaled, y_train, batch_size = 10, epochs = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9efk-yJKD9Df",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#measure accuracy on test data\n",
        "y_pred = classifier2.predict(X_test_scaled)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgOZcWpOD9GU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#measure accuracy on training data\n",
        "y_pred = classifier2.predict(wrong_x)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(accuracy_score(wrong_y, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBVVcRX9D9MK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generate error images\n",
        "wrong_index2, wrong_x2, wrong_y2 = generate_error_imgs2(y_pred, wrong_x, wrong_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxWa_XQHD9PD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert to arrays\n",
        "wrong_x2 = np.array(wrong_x2)\n",
        "wrong_y2 = np.array(wrong_y2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK8UKHmHD9SL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create Third Model\n",
        "# Initialising the ANN\n",
        "classifier3 = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier3.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu', input_dim = 16))\n",
        "\n",
        "classifier3.add(Dropout(0.5))\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier3.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "# Adding the output layer\n",
        "classifier3.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "\n",
        "# Compiling the ANN\n",
        "classifier3.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "classifier3.fit(wrong_x2, wrong_y2, batch_size = 10, epochs = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L-aqBxlD9VY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fine-tune on original data\n",
        "classifier3.fit(X_train_scaled, y_train, batch_size = 10, epochs = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCUOfdQAEgFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#measure accuracy on test data\n",
        "y_pred = classifier3.predict(X_test_scaled)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZulTeFaEgOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#measure accuracy on training data\n",
        "y_pred = classifier3.predict(wrong_x2)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(accuracy_score(wrong_y2, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2xCv74iG6pL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generate error images\n",
        "wrong_index3, wrong_x3, wrong_y3 = generate_error_imgs2(y_pred, wrong_x2, wrong_y2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2vjmFlMHIcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert to arrays\n",
        "wrong_x3 = np.array(wrong_x3)\n",
        "wrong_y3 = np.array(wrong_y3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyRm_x53Hg0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fine-tune first model on last one's missed data\n",
        "classifier.fit(wrong_x3, wrong_y3, batch_size = 10, epochs = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g14WQOmiEgTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get final predictions for all\n",
        "firstpred = classifier.predict(X_train_scaled)\n",
        "secondpred = classifier2.predict(X_train_scaled)\n",
        "thirdpred = classifier3.predict(X_train_scaled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5dCodkgEgV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create master dataset\n",
        "master = []\n",
        "for i in range(len(X_train)):\n",
        "  one = [None] * 3\n",
        "  one[0] = firstpred[i][0]\n",
        "  one[1] = secondpred[i][0]\n",
        "  one[2] = thirdpred[i][0]\n",
        "  master.append(one)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWzYtEncEgYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create master arrays\n",
        "master = np.array(master)\n",
        "y_train = np.array(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TchQeVm0Eggj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#even out classes\n",
        "zcount = 0\n",
        "wcount = 0\n",
        "indexes = []\n",
        "for num in range(len(y_train)):\n",
        "  if y_train[num] == 0:\n",
        "    if zcount < 10000:\n",
        "      indexes.append(num)\n",
        "      zcount += 1\n",
        "  elif y_train[num] == 1:\n",
        "    if wcount < 10000:\n",
        "      indexes.append(num)\n",
        "      wcount += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02EevQeGEgmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create even classes\n",
        "fm = []\n",
        "fy = []\n",
        "for num in indexes:\n",
        "  fm.append(master[num])\n",
        "  fy.append(y_train[num])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IoZQTImEgpE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create final arrays\n",
        "fm = np.array(fm)\n",
        "fy = np.array(fy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq5mcCfLEguW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train final classifier\n",
        "# Initialising the ANN\n",
        "mclassifier = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "mclassifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = 3))\n",
        "\n",
        "mclassifier.add(Dropout(0.5))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "mclassifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "# Adding the output layer\n",
        "mclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "\n",
        "# Compiling the ANN\n",
        "mclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "mclassifier.fit(fm, fy, batch_size = 10, epochs = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0gayS6wEg0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make test predictions\n",
        "firstpred2 = classifier.predict(X_test)\n",
        "secondpred2 = classifier2.predict(X_test)\n",
        "thirdpred2 = classifier3.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E67y4ePGEgrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create master test dataset\n",
        "master2 = []\n",
        "for i in range(len(X_test)):\n",
        "  one2 = [None] * 3\n",
        "  one2[0] = firstpred2[i][0]\n",
        "  one2[1] = secondpred2[i][0]\n",
        "  one2[2] = thirdpred2[i][0]\n",
        "  master2.append(one2)\n",
        "master2 = np.array(master2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDX3aLu2Egj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get final accuracy\n",
        "finalpred = mclassifier.predict(master2)\n",
        "finalpred = (finalpred > 0.5)\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "report = classification_report(y_test, finalpred)\n",
        "print(report) \n",
        "print(confusion_matrix(y_test,finalpred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viqN70uACqDf",
        "colab_type": "text"
      },
      "source": [
        "# Section 3 - Multiclass Machine Learning Classification\n",
        "\n",
        "This section tested the architecture against a multiclass Forest Covertype dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-QsGx4tFZFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import dataset\n",
        "from sklearn.datasets import fetch_covtype\n",
        "cov_data = fetch_covtype()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVTHY3o9FZPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#separate y-data into classes\n",
        "cv1 = []\n",
        "cv2 = []\n",
        "cv3 = []\n",
        "cv4 = []\n",
        "cv5 = []\n",
        "cv6 = []\n",
        "cv7 = []\n",
        "for num in range(len(cov_data.target)):\n",
        "  if cov_data.target[num] == 1:\n",
        "    cv1.append(num)\n",
        "  elif cov_data.target[num] == 2:\n",
        "    cv2.append(num)\n",
        "  elif cov_data.target[num] == 3:\n",
        "    cv3.append(num)\n",
        "  elif cov_data.target[num] == 4:\n",
        "    cv4.append(num)\n",
        "  elif cov_data.target[num] == 5:\n",
        "    cv5.append(num)\n",
        "  elif cov_data.target[num] == 6:\n",
        "    cv6.append(num)\n",
        "  elif cov_data.target[num] == 7:\n",
        "    cv7.append(num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEbDU8aLFZVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#separate x-data into classes\n",
        "rcv1 = []\n",
        "rcv2 = []\n",
        "rcv3 = []\n",
        "rcv4 = []\n",
        "rcv5 = []\n",
        "rcv6 = []\n",
        "rcv7 = []\n",
        "for num in cv1:\n",
        "  rcv1.append(cov_data.data[num])\n",
        "for num in cv2:\n",
        "  rcv2.append(cov_data.data[num])\n",
        "for num in cv3:\n",
        "  rcv3.append(cov_data.data[num])\n",
        "for num in cv4:\n",
        "  rcv4.append(cov_data.data[num])\n",
        "for num in cv5:\n",
        "  rcv5.append(cov_data.data[num])\n",
        "for num in cv6:\n",
        "  rcv6.append(cov_data.data[num])\n",
        "for num in cv7:\n",
        "  rcv7.append(cov_data.data[num])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpzz3l_IFZbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#even out classes\n",
        "from sklearn.utils import resample\n",
        "ncv1 = resample(rcv1,\n",
        "               replace=False,\n",
        "               n_samples=2747,\n",
        "               random_state=42)\n",
        "ncv2 = resample(rcv2,\n",
        "               replace=False,\n",
        "               n_samples=2747,\n",
        "               random_state=42)\n",
        "ncv3 = resample(rcv3,\n",
        "               replace=False,\n",
        "               n_samples=2747,\n",
        "               random_state=42)\n",
        "ncv4 = resample(rcv4,\n",
        "               replace=False,\n",
        "               n_samples=2747,\n",
        "               random_state=42)\n",
        "ncv5 = resample(rcv5,\n",
        "               replace=False,\n",
        "               n_samples=2747,\n",
        "               random_state=42)\n",
        "ncv6 = resample(rcv6,\n",
        "               replace=False,\n",
        "               n_samples=2747,\n",
        "               random_state=42)\n",
        "ncv7 = resample(rcv7,\n",
        "               replace=False,\n",
        "               n_samples=2747,\n",
        "               random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wjtu5C4jFZf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create master datasets\n",
        "import numpy as np\n",
        "master = np.concatenate((ncv1,ncv2,ncv3,ncv4,ncv5,ncv6,ncv7))\n",
        "mastert = np.concatenate((2747*[1], 2747*[2], 2747*[3], 2747*[4], 2747*[5], 2747*[6], 2747*[7]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj9Xa3xMFZtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create training and test data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "X, y = master, mastert\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "import numpy as np\n",
        "newy_train = []\n",
        "for i in y_train:\n",
        "  f = []\n",
        "  f.append(i-1)\n",
        "  newy_train.append(f)\n",
        "  \n",
        "newy_test = []\n",
        "for i in y_test:\n",
        "  f = []\n",
        "  f.append(i-1)\n",
        "  newy_test.append(f)\n",
        "\n",
        "newy_train = np.array(newy_train)\n",
        "newy_test = np.array(newy_test)\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "print(newy_test)\n",
        "y_cat_test = to_categorical(newy_test,7)\n",
        "y_cat_train = to_categorical(newy_train,7)\n",
        "print(y_cat_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8lVLVTpFZw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create first model\n",
        "# Initialising the ANN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu', input_dim = 54))\n",
        "\n",
        "classifier.add(Dropout(0.5))\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "\n",
        "# Adding the output layer\n",
        "classifier.add(Dense(units = 7, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "\n",
        "# Compiling the ANN\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "classifier.fit(X_train_scaled, y_cat_train, batch_size = 10, epochs = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozKDIHWkFZ0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scale data and make predictions, get accuracy\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "y_pred = classifier.predict(X_test_scaled)\n",
        "rounded_predictions = y_pred.copy()\n",
        "rounded_real = []\n",
        "for item in rounded_predictions:\n",
        "    maxx = max(item)\n",
        "    rounded_real.append(np.where(item==maxx)[0][0])\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(accuracy_score(newy_test, rounded_real))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j0YBUDUFZ4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define incorrect data function\n",
        "def generate_error_imgs2(predictions, orig_imgs, real_values):\n",
        "  index = -1\n",
        "  count = 0\n",
        "  wrong_img_indexes = []\n",
        "  wrong_img_list = []\n",
        "  wrong_img_class_list = []\n",
        "  for item in predictions:\n",
        "    index+=1\n",
        "    if item != real_values[index]:\n",
        "      count +=1\n",
        "      wrong_img_indexes.append(index)\n",
        "  print(count)\n",
        "  for index2 in wrong_img_indexes:\n",
        "    wrong_img_list.append(orig_imgs[index2])\n",
        "    wrong_img_class_list.append(real_values[index2])\n",
        "      \n",
        "  return wrong_img_indexes, wrong_img_list,wrong_img_class_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Csb6pTesFZ8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get accuracy on training data\n",
        "y_pred = classifier.predict(X_train_scaled)\n",
        "rounded_predictions = y_pred.copy()\n",
        "rounded_real = []\n",
        "for item in rounded_predictions:\n",
        "    maxx = max(item)\n",
        "    rounded_real.append(np.where(item==maxx)[0][0])\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(accuracy_score(newy_train, rounded_real))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z92Zntn3FaAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generate incorrect data\n",
        "import numpy as np\n",
        "wrong_index, wrong_x, wrong_y = generate_error_imgs2(rounded_real,X_train_scaled, newy_train)\n",
        "wrong_x = np.array(wrong_x)\n",
        "wrong_y = np.array(wrong_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXtkeUcpFaE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert data to categorical data\n",
        "from keras.utils.np_utils import to_categorical\n",
        "print(wrong_y)\n",
        "y_cat_wrong = to_categorical(wrong_y,7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nS97PdBiFaYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create second model\n",
        "# Initialising the ANN\n",
        "classifier2 = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier2.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu', input_dim = 54))\n",
        "\n",
        "classifier2.add(Dropout(0.5))\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier2.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "\n",
        "# Adding the output layer\n",
        "classifier2.add(Dense(units = 7, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "\n",
        "# Compiling the ANN\n",
        "classifier2.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "classifier2.fit(wrong_x, y_cat_wrong, batch_size = 10, epochs = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrW5nssZFahH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fine-tune model\n",
        "classifier2.fit(X_train_scaled, y_cat_train, batch_size = 10, epochs = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VngqD6pPFap0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get accuracy\n",
        "y_pred = classifier2.predict(X_test_scaled)\n",
        "rounded_predictions = y_pred.copy()\n",
        "rounded_real = []\n",
        "for item in rounded_predictions:\n",
        "    maxx = max(item)\n",
        "    rounded_real.append((np.where(item==maxx)[0][0]))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(accuracy_score(newy_test, rounded_real))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFtqOA_2Fawc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get accuracy on training data\n",
        "y_pred = classifier2.predict(wrong_x)\n",
        "rounded_predictions = y_pred.copy()\n",
        "rounded_real = []\n",
        "for item in rounded_predictions:\n",
        "    maxx = max(item)\n",
        "    rounded_real.append((np.where(item==maxx)[0][0]))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(accuracy_score(wrong_y, rounded_real))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEEHFSJvFZp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generate incorrect data\n",
        "wrong_index2, wrong_x2, wrong_y2 = generate_error_imgs2(rounded_real,wrong_x, wrong_y)\n",
        "wrong_x2 = np.array(wrong_x2)\n",
        "wrong_y2 = np.array(wrong_y2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwFHzPpbYxbe",
        "colab_type": "code",
        "outputId": "31bb5e47-ac62-43b3-8b30-c7bf7ebb6de4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "#convert to categorical\n",
        "from keras.utils.np_utils import to_categorical\n",
        "print(wrong_y2)\n",
        "y_cat_wrong2 = to_categorical(wrong_y2,7)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2]\n",
            " [6]\n",
            " [1]\n",
            " ...\n",
            " [2]\n",
            " [4]\n",
            " [4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqqQNnj8K3C4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create third model\n",
        "# Initialising the ANN\n",
        "classifier3 = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier3.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu', input_dim = 54))\n",
        "\n",
        "classifier3.add(Dropout(0.5))\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier3.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "\n",
        "# Adding the output layer\n",
        "classifier3.add(Dense(units = 7, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "\n",
        "# Compiling the ANN\n",
        "classifier3.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "classifier3.fit(wrong_x2, y_cat_wrong2, batch_size = 10, epochs = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF3CJbhvK3Lk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fine-tune third model on original data\n",
        "classifier3.fit(X_train_scaled, y_cat_train, batch_size = 10, epochs = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL6lBbTMK3Up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get accuracy on test data\n",
        "y_pred = classifier3.predict(X_test_scaled)\n",
        "rounded_predictions = y_pred.copy()\n",
        "rounded_real = []\n",
        "for item in rounded_predictions:\n",
        "    maxx = max(item)\n",
        "    rounded_real.append((np.where(item==maxx)[0][0]))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(accuracy_score(newy_test, rounded_real))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeNr1JuDK3fT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get accuracy on training data\n",
        "y_pred = classifier3.predict(wrong_x2)\n",
        "rounded_predictions = y_pred.copy()\n",
        "rounded_real = []\n",
        "for item in rounded_predictions:\n",
        "    maxx = max(item)\n",
        "    rounded_real.append((np.where(item==maxx)[0][0]))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(accuracy_score(wrong_y2, rounded_real))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMXTD3DmM3Bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generate incorrect data\n",
        "wrong_index3, wrong_x3, wrong_y3 = generate_error_imgs2(rounded_real,wrong_x2, wrong_y2)\n",
        "wrong_x3 = np.array(wrong_x3)\n",
        "wrong_y3 = np.array(wrong_y3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8lvFvFdNADE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert to categorical\n",
        "from keras.utils.np_utils import to_categorical\n",
        "print(wrong_y3)\n",
        "y_cat_wrong3 = to_categorical(wrong_y3,7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOfAeNm6NHqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fine-tune first model on incorrect data\n",
        "classifier3.fit(wrong_x3, y_cat_wrong3, batch_size = 10, epochs = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-4RrwDrK3sH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get final predictions\n",
        "firstpred = classifier.predict(X_train_scaled)\n",
        "secondpred = classifier2.predict(X_train_scaled)\n",
        "thirdpred = classifier3.predict(X_train_scaled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASHTcS7gK3wN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create master data\n",
        "master = []\n",
        "for i in range(len(X_train_scaled)):\n",
        "  one = [None] * 21\n",
        "  one[0] = firstpred[i][0]\n",
        "  one[1] = firstpred[i][1]\n",
        "  one[2] = firstpred[i][2]\n",
        "  one[3] = firstpred[i][3]\n",
        "  one[4] = firstpred[i][4]\n",
        "  one[5] = firstpred[i][5]\n",
        "  one[6] = firstpred[i][6]\n",
        "  one[7] = secondpred[i][0]\n",
        "  one[8] = secondpred[i][1]\n",
        "  one[9] = secondpred[i][2]\n",
        "  one[10] = secondpred[i][3]\n",
        "  one[11] = secondpred[i][4]\n",
        "  one[12] = secondpred[i][5]\n",
        "  one[13] = secondpred[i][6]\n",
        "  one[14] = thirdpred[i][0]\n",
        "  one[15] = thirdpred[i][1]\n",
        "  one[16] = thirdpred[i][2]\n",
        "  one[17] = thirdpred[i][3]\n",
        "  one[18] = thirdpred[i][4]\n",
        "  one[19] = thirdpred[i][5]\n",
        "  one[20] = thirdpred[i][6]\n",
        "  master.append(one)\n",
        "master = np.array(master)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pM5-jL4K344",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create final model\n",
        "# Initialising the ANN\n",
        "mclassifier = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "mclassifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu', input_dim = 21))\n",
        "\n",
        "mclassifier.add(Dropout(.5))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "mclassifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "# Adding the output layer\n",
        "mclassifier.add(Dense(units = 7, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "\n",
        "# Compiling the ANN\n",
        "mclassifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "mclassifier.fit(master, y_cat_train, batch_size = 10, epochs = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5qvHmwAK3_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create master test data\n",
        "firstpred = classifier.predict(X_test_scaled)\n",
        "secondpred = classifier2.predict(X_test_scaled)\n",
        "thirdpred = classifier3.predict(X_test_scaled)\n",
        "master2 = []\n",
        "for i in range(len(X_test)):\n",
        "  one = [None] * 21\n",
        "  one[0] = firstpred[i][0]\n",
        "  one[1] = firstpred[i][1]\n",
        "  one[2] = firstpred[i][2]\n",
        "  one[3] = firstpred[i][3]\n",
        "  one[4] = firstpred[i][4]\n",
        "  one[5] = firstpred[i][5]\n",
        "  one[6] = firstpred[i][6]\n",
        "  one[7] = secondpred[i][0]\n",
        "  one[8] = secondpred[i][1]\n",
        "  one[9] = secondpred[i][2]\n",
        "  one[10] = secondpred[i][3]\n",
        "  one[11] = secondpred[i][4]\n",
        "  one[12] = secondpred[i][5]\n",
        "  one[13] = secondpred[i][6]\n",
        "  one[14] = thirdpred[i][0]\n",
        "  one[15] = thirdpred[i][1]\n",
        "  one[16] = thirdpred[i][2]\n",
        "  one[17] = thirdpred[i][3]\n",
        "  one[18] = thirdpred[i][4]\n",
        "  one[19] = thirdpred[i][5]\n",
        "  one[20] = thirdpred[i][6]\n",
        "  master2.append(one)\n",
        "master2 = np.array(master2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3ooYFX9K4D7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get final accuracy\n",
        "y_pred = mclassifier.predict(master2)\n",
        "rounded_predictions = y_pred.copy()\n",
        "rounded_real = []\n",
        "for item in rounded_predictions:\n",
        "    maxx = max(item)\n",
        "    rounded_real.append((np.where(item==maxx)[0][0]))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "report = classification_report(newy_test, rounded_real)\n",
        "print(report) \n",
        "print(confusion_matrix(newy_test,rounded_real))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}